train_loss,val_loss,curr_epoch
0.1659404,0.19866991,0
0.12968399,0.1165733,1
0.12026748,0.11449023,2
0.11584981,0.11128596,3
0.11303287,0.11249738,4
0.10990912,0.10569699,5
0.10834349,0.10761044,6
0.103369884,0.10103007,7
0.101488575,0.15551478,8
0.099321924,0.10497954,9
0.09669233,0.10367713,10
0.09408937,0.15045,11
0.09387467,0.16343108,12
0.09444003,0.09614175,13
0.090532094,0.11136641,14
0.08901918,0.121868886,15
0.087550856,0.076236896,16
0.085291564,0.19391859,17
0.096388385,0.09689957,18
0.08667314,0.08445725,19
0.082513094,0.12310797,20
0.08484572,0.104146674,21
0.08220258,0.10933506,22
0.08071251,0.09082051,23
0.079271,0.08198838,24
0.07867477,0.08553087,25
0.07743374,0.09265309,26
0.07783473,0.09151273,27
0.077083044,0.11705178,28
0.077767275,0.08605972,29
0.07424589,0.08023904,30
0.075689904,0.11404867,31
0.07454898,0.07802107,32
0.073417865,0.08149241,33
0.07414427,0.106637806,34
0.07339706,0.10338632,35
0.07346695,0.08302978,36
0.0718559,0.121516615,37
0.07127798,0.08858409,38
0.06982647,0.074893,39
0.06866433,0.14091001,40
0.07242757,0.11521068,41
0.069554985,0.3018441,42
0.073281,0.092452265,43
0.070103645,0.079224385,44
0.06923408,0.077603064,45
0.06699758,0.07439042,46
0.067167014,0.08712456,47
0.06731969,0.08674805,48
0.06601856,0.07401556,49
0.06615368,0.1943727,50
0.070528805,0.076252505,51
0.06559257,0.07215973,52
0.06452103,0.077820584,53
0.06589819,0.069058426,54
0.064677246,0.105434895,55
0.065250576,0.0933048,56
0.0637914,0.0779201,57
0.06512692,0.11046213,58
0.0641076,0.07742888,59
0.062621176,0.091015525,60
0.06255885,0.07575319,61
0.06184356,0.14712891,62
0.065524854,0.07541942,63
0.062062923,0.07244087,64
0.060901653,0.09260625,65
0.060813952,0.097597234,66
0.06271866,0.10998783,67
0.063550815,0.11363352,68
0.06119267,0.088361785,69
0.060687736,0.07739707,70
0.060000684,0.06946512,71
0.059927113,0.11023313,72
0.05949508,0.08964158,73
0.059699047,0.069863774,74
0.05855638,0.07040902,75
