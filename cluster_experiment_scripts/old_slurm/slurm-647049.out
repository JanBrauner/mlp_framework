sending incremental file list
use 6 GPU(s)
  0%|          | 0/29 [00:00<?, ?it/s][('continue_from_epoch', '-1'), ('seed', '0'), ('task', 'classification'), ('use_gpu', 'True'), ('gpu_id', '0,1,2,4,5,6'), ('model_name', 'context_encoder'), ('kernel_size', '4'), ('num_layers_enc', '6'), ('num_channels_enc', '64'), ('num_channels_progression_enc', '[1, 1, 2, 4, 8]'), ('num_channels_bottleneck', '8192'), ('num_layers_dec', '6'), ('num_channels_dec', '64'), ('num_channels_progression_dec', '[8, 4, 2, 1, 1]'), ('dataset_name', 'MiasHealthy'), ('num_image_channels', '1'), ('image_height', '128'), ('image_width', '128'), ('normalisation', 'range-11'), ('scale_image', '[1, 1]'), ('data_format', 'autoencoding'), ('debug_mode', 'False'), ('num_workers', '12'), ('augment', 'True'), ('gamma_factor', '1'), ('rot_angle', '15'), ('translate_factor', '[0, 0]'), ('scale_factor', '1.2'), ('shear_angle', '6'), ('patch_mode', 'True'), ('patch_size', '[128, 128]'), ('patch_location_during_training', 'random'), ('patch_rejection_threshold', '10'), ('image_padding_mode', 'None'), ('mask_size', '[64, 64]'), ('batch_size', '50'), ('loss', 'cross_entropy'), ('num_epochs', '200'), ('learning_rate', '0.0002'), ('betas', '[0.5, 0.999]'), ('weight_decay_coefficient', '0'), ('anomaly_dataset_name', 'MiasPathological'), ('AD_patch_stride', '[10, 10]'), ('measure_of_anomaly', 'likelihood'), ('window_aggregation_method', 'mean'), ('save_anomaly_maps', 'True'), ('AD_margins', 'None'), ('AD_batch_size', '50'), ('experiment_name', 'r8_AE_Mias_prob_bn_8192_scale_1')]
Loading data from:  /disk/scratch/s1890594/data/MiasHealthy
Loading data from:  /disk/scratch/s1890594/data/MiasHealthy
Loading data from:  /disk/scratch/s1890594/data/MiasHealthy
/mnt/mscteach_home/s1890594/mlp_framework/results/r8_AE_Mias_prob_bn_8192_scale_1 /mnt/mscteach_home/s1890594/mlp_framework/results/r8_AE_Mias_prob_bn_8192_scale_1/result_outputs
  3%|▎         | 1/29 [00:43<20:27, 43.83s/it]loss: 5.5762, accuracy: 0.0037:   3%|▎         | 1/29 [00:43<20:27, 43.83s/it]
Traceback (most recent call last):
  File "main.py", line 54, in <module>
    experiment_metrics, test_metrics = experiment.run_experiment()  
  File "/mnt/mscteach_home/s1890594/mlp_framework/experiment_builder.py", line 252, in run_experiment
    loss, accuracy, map_mse_range11 = self.run_train_iter(x=x, y=y)  # take a training iter step
  File "/mnt/mscteach_home/s1890594/mlp_framework/experiment_builder.py", line 122, in run_train_iter
    loss.backward()  # backpropagate to compute gradients for current iter loss
  File "/home/s1890594/miniconda3/envs/mlp/lib/python3.7/site-packages/torch/tensor.py", line 107, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/s1890594/miniconda3/envs/mlp/lib/python3.7/site-packages/torch/autograd/__init__.py", line 93, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 800.00 MiB (GPU 0; 5.94 GiB total capacity; 4.48 GiB already allocated; 777.31 MiB free; 246.84 MiB cached)
