sending incremental file list
use 6 GPU(s)
  0%|          | 0/76 [00:00<?, ?it/s][('continue_from_epoch', '-1'), ('seed', '0'), ('task', 'classification'), ('use_gpu', 'True'), ('gpu_id', '0,1,2,3,4,5'), ('model_name', 'context_encoder'), ('kernel_size', '4'), ('num_layers_enc', '6'), ('num_channels_enc', '64'), ('num_channels_progression_enc', '[1, 1, 2, 4, 8]'), ('num_channels_bottleneck', '128'), ('num_layers_dec', '6'), ('num_channels_dec', '64'), ('num_channels_progression_dec', '[8, 4, 2, 1, 1]'), ('dataset_name', 'DescribableTextures'), ('num_image_channels', '3'), ('image_height', '128'), ('image_width', '128'), ('normalisation', 'range-11'), ('scale_image', 'None'), ('data_format', 'autoencoding'), ('debug_mode', 'False'), ('num_workers', '12'), ('augment', 'False'), ('gamma_factor', '1'), ('rot_angle', '0'), ('translate_factor', '[0, 0]'), ('scale_factor', '1'), ('shear_angle', '0'), ('patch_mode', 'False'), ('patch_size', '[128, 128]'), ('patch_location_during_training', 'random'), ('patch_rejection_threshold', '10'), ('image_padding_mode', 'None'), ('mask_size', '[64, 64]'), ('batch_size', '50'), ('loss', 'cross_entropy'), ('num_epochs', '200'), ('learning_rate', '0.0002'), ('betas', '[0.5, 0.999]'), ('weight_decay_coefficient', '0'), ('anomaly_dataset_name', 'DTPathologicalIrreg1'), ('AD_patch_stride', '[10, 10]'), ('measure_of_anomaly', 'likelihood'), ('window_aggregation_method', 'mean'), ('save_anomaly_maps', 'True'), ('AD_margins', '[128, 128]'), ('AD_batch_size', '50'), ('experiment_name', 'AE_DTD_r3_prob_full_image_128_bn_128')]
Loading data from:  /disk/scratch/s1890594/data/DescribableTextures
Loading data from:  /disk/scratch/s1890594/data/DescribableTextures
Loading data from:  /disk/scratch/s1890594/data/DescribableTextures
/mnt/mscteach_home/s1890594/mlp_framework/results/AE_DTD_r3_prob_full_image_128_bn_128 /mnt/mscteach_home/s1890594/mlp_framework/results/AE_DTD_r3_prob_full_image_128_bn_128/result_outputs

Traceback (most recent call last):
  File "main.py", line 54, in <module>
    experiment_metrics, test_metrics = experiment.run_experiment()  
  File "/mnt/mscteach_home/s1890594/mlp_framework/experiment_builder.py", line 252, in run_experiment
    loss, accuracy, map_mse_range11 = self.run_train_iter(x=x, y=y)  # take a training iter step
  File "/mnt/mscteach_home/s1890594/mlp_framework/experiment_builder.py", line 122, in run_train_iter
    loss.backward()  # backpropagate to compute gradients for current iter loss
  File "/home/s1890594/miniconda3/envs/mlp/lib/python3.7/site-packages/torch/tensor.py", line 107, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/s1890594/miniconda3/envs/mlp/lib/python3.7/site-packages/torch/autograd/__init__.py", line 93, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 2.34 GiB (GPU 0; 5.94 GiB total capacity; 4.79 GiB already allocated; 697.31 MiB free; 10.05 MiB cached)
